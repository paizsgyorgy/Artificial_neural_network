{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Artificial Neural Network (ANN) from scratch: a feed-forward model example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A feedforward neural network is an artificial neural network wherein connections between the nodes do not form a cycle. As such, it is \n",
    "different from recurrent neural networks. \n",
    "\n",
    "The feedforward neural network was the first and simplest type of artificial neural network devised. In this network, the information moves in only one direction, forward, from the input nodes, through the hidden nodes (if any) and to the output nodes. There are no cycles or loops in the network.\n",
    "\n",
    "(Source: wikipedia.com, illustration: learnopencv.com)\n",
    "\n",
    "<img src=\"https://www.learnopencv.com/wp-content/uploads/2017/10/mlp-diagram.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: *We'll start with making some random data with the make_moons method in Scikit Learn*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import all necessary packages\n",
    "from sklearn.datasets import make_moons\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import e\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data from sklearn datasets\n",
    "X, y = make_moons(n_samples=50, noise=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visalizing the make_moons dataset that we will want our model to correctly categorize after some training\n",
    "plt.scatter(X[:,0], X[:,1], c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: *Define the activiation function - we will use a sigmoid function in our NN model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Activation function 1\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + e ** -x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Activation function 2 (this is optional - just as an example of a different activation function)\n",
    "def tanh(x):\n",
    "    return (e**x - e**-x) / (e**x + e**-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *In addition to the data X and y, we also need to initialize random weights for our model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the first layer of weights and verify that they have a shape of (3,2)\n",
    "weights0 = np.random.rand(3,2)\n",
    "assert weights0.shape == (3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create second layer of weights and verify that they have a shape of (3,1)\n",
    "weights1 = np.random.rand(3,1)\n",
    "assert weights1.shape == (3,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: *Implement the Feed-Forward Function with one hidden layer and sigmoid activation functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward_sigmoid(X, weights0, weights1):\n",
    "    ## 1: X data is (50,2)\n",
    "    \n",
    "    ## 2: add a bias columns, so X turns from (50,2) to (50,3) with added 1s\n",
    "    X = np.hstack((X,np.ones((X.shape[0],1))))\n",
    "    \n",
    "    ## 3: dot product of X with weights0\n",
    "    d1 = np.dot(X, weights0)\n",
    "    \n",
    "    ## 4: apply sigmoid activation function to each value in d1\n",
    "    s1 = sigmoid(d1)\n",
    "    \n",
    "    ## 5: add bias column to the hidden layer -> this makes it (50,3), incl. bias\n",
    "    h1 = np.hstack((s1, np.ones((s1.shape[0],1))))\n",
    "    \n",
    "    ## 6: dot pdocut of hidden layer h1 and weights1\n",
    "    d2 = np.dot(h1, weights1)\n",
    "    \n",
    "    ## 7: apply sigmoid function to get the output layer\n",
    "    o2 = sigmoid(d2)\n",
    "    \n",
    "    return h1, o2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So we just made a simple, 2-layer neural network from scratch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementing this feed forward results in a set of probabilities\n",
    "hidden_layer, y_prob = feed_forward_sigmoid(X, weights0, weights1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's look at the actual predictions and accuracy score\n",
    "def predict(output_probabilities):\n",
    "    return np.array([np.round(x) for x in output_probabilities])\n",
    "\n",
    "y_pred = predict(y_prob).flatten()\n",
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **The predictions do not look too good due to the randomly initialized weights...our model still needs to be trained!**\n",
    "\n",
    "#### Training of the model will use a backpropagation algorythm described in the ANN_backprop_training notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
